import sounddevice as sdimport soundfile as sfimport opensmileimport joblibimport pandas as pdimport timeimport jsonDURATION = 3  # 錄音秒數FS = 16000    # 採樣率MODEL_PATH = "emotion_model.joblib"OUTPUT_JSON = "current_emotion.json"# 初始化print("🌀 情緒偵測器啟動中...")model = joblib.load(MODEL_PATH)smile = opensmile.Smile(    feature_set=opensmile.FeatureSet.eGeMAPSv02,    feature_level=opensmile.FeatureLevel.Functionals,)while True:    print("🎙️ 錄音中，請說話...")    recording = sd.rec(int(DURATION * FS), samplerate=FS, channels=1)    sd.wait()    sf.write("recorded.wav", recording, FS)    print("🔍 擷取聲音特徵...")    features = smile.process_file("recorded.wav")    features.columns = features.columns.astype(str)  # 防止欄位錯誤    # 預測情緒    prediction = model.predict(features)[0]    confidence = max(model.predict_proba(features)[0])  # 拿最大信心度    print(f"💡 偵測到的情緒: {prediction}（信心度 {confidence:.2f}）")    # 寫入 JSON 給 Unity    result = {        "emotion": prediction,        "confidence": round(float(confidence), 3),    }    with open(OUTPUT_JSON, "w") as f:        json.dump(result, f)    # 等幾秒再繼續    time.sleep(1)