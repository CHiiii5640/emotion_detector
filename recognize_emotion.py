import sounddevice as sdimport soundfile as sfimport opensmileimport joblibimport pandas as pdimport timeimport jsonDURATION = 3  # éŒ„éŸ³ç§’æ•¸FS = 16000    # æ¡æ¨£ç‡MODEL_PATH = "emotion_model.joblib"OUTPUT_JSON = "current_emotion.json"# åˆå§‹åŒ–print("ğŸŒ€ æƒ…ç·’åµæ¸¬å™¨å•Ÿå‹•ä¸­...")model = joblib.load(MODEL_PATH)smile = opensmile.Smile(    feature_set=opensmile.FeatureSet.eGeMAPSv02,    feature_level=opensmile.FeatureLevel.Functionals,)while True:    print("ğŸ™ï¸ éŒ„éŸ³ä¸­ï¼Œè«‹èªªè©±...")    recording = sd.rec(int(DURATION * FS), samplerate=FS, channels=1)    sd.wait()    sf.write("recorded.wav", recording, FS)    print("ğŸ” æ“·å–è²éŸ³ç‰¹å¾µ...")    features = smile.process_file("recorded.wav")    features.columns = features.columns.astype(str)  # é˜²æ­¢æ¬„ä½éŒ¯èª¤    # é æ¸¬æƒ…ç·’    prediction = model.predict(features)[0]    confidence = max(model.predict_proba(features)[0])  # æ‹¿æœ€å¤§ä¿¡å¿ƒåº¦    print(f"ğŸ’¡ åµæ¸¬åˆ°çš„æƒ…ç·’: {prediction}ï¼ˆä¿¡å¿ƒåº¦ {confidence:.2f}ï¼‰")    # å¯«å…¥ JSON çµ¦ Unity    result = {        "emotion": prediction,        "confidence": round(float(confidence), 3),    }    with open(OUTPUT_JSON, "w") as f:        json.dump(result, f)    # ç­‰å¹¾ç§’å†ç¹¼çºŒ    time.sleep(1)